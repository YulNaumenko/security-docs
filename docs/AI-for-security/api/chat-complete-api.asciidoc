[[chat-complete-api]]
== Chat Complete API

The Chat Complete API lets you create new Elastic AI Assistant conversations, and add messages to existing conversations.

[discrete]
=== Request URL

`POST <kibana host>:<port>//api/security_ai_assistant/chat/complete`

[discrete]
=== Request body

<DocTable columns={[
  {
    "title": "Name",
    "width": "30%"
  },
  {
    "title": "Type",
    "width": "20%"
  },
  {
    "title": "Description",
    "width": "50%"
  }
]}>
  promptId: z.string().optional(),
  isStream: z.boolean().optional(),
  responseLanguage: z.string().optional(),
  langSmithProject: z.string().optional(),
  langSmithApiKey: z.string().optional(),
  connectorId: z.string(),
  model: z.string().optional(),
  persist: z.boolean(),
  messages: z.array(ChatMessage),
  <DocRow>
    <DocCell>`conversationId`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      (Optional) Conversation id to which append the messages and use as a context.
      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`promptId`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Default conversation propmt Id
      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`persist`</DocCell>
    <DocCell>Boolean</DocCell>
    <DocCell>
      Define if conversation should be created or updated.
      
    </DocCell>
  </DocRow>
  </DocRow>
  <DocRow>
    <DocCell>`messages`</DocCell>
    <DocCell><DocLink slug="/AI-for-security/api/conversation-api-create" section="message-object">Array<Message></DocLink></DocCell>
    <DocCell>
      Array of conversation messages.
      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`model`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      List of the fields with anonymization.
      
    </DocCell>
  </DocRow>
</DocTable>

<div id="apiConfig-obj"></div>

[discrete]
=== ApiConfig object

<DocTable columns={[
  {
    "title": "Name",
    "width": "30%"
  },
  {
    "title": "Type",
    "width": "20%"
  },
  {
    "title": "Description",
    "width": "50%"
  }
]}>
  <DocRow>
    <DocCell>`connectorId`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Kibana connector ID

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`actionTypeId`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Kibana connector ation type ID

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`defaultSystemPromptId`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Default system prompt ID

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`model`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      LLM specific model

      
    </DocCell>
  </DocRow>
</DocTable>

<div id="message-obj"></div>

[discrete]
=== Message object

<DocTable columns={[
  {
    "title": "Name",
    "width": "30%"
  },
  {
    "title": "Type",
    "width": "20%"
  },
  {
    "title": "Description",
    "width": "50%"
  }
]}>
  <DocRow>
    <DocCell>`role`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Message role. Could be "user", "assisatnt" or "system".

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`content`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Message content tot send to LLM

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`isError`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Define if the message is an error message and not LLM response.

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`timestamp`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Timestamp when the message was sent.

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`traceData`</DocCell>
    <DocCell>Object</DocCell>
    <DocCell>
      Tracing information.

      
    </DocCell>
  </DocRow>
</DocTable>

<div id="message-obj"></div>

[discrete]
=== Replacements object

<DocTable columns={[
  {
    "title": "Name",
    "width": "30%"
  },
  {
    "title": "Type",
    "width": "20%"
  },
  {
    "title": "Description",
    "width": "50%"
  }
]}>
  <DocRow>
    <DocCell>`role`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Message role. Could be "user", "assisatnt" or "system".

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`content`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Message content tot send to LLM

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`isError`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Define if the message is an error message and not LLM response.

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`timestamp`</DocCell>
    <DocCell>String</DocCell>
    <DocCell>
      Timestamp when the message was sent.

      
    </DocCell>
  </DocRow>
  <DocRow>
    <DocCell>`traceData`</DocCell>
    <DocCell>Object</DocCell>
    <DocCell>
      Tracing information.

      
    </DocCell>
  </DocRow>
</DocTable>

[discrete]
=== Example requests

*Example 1*

Creates a new Conversation.

[source,console]
--------------------------------------------------
POST api/security_ai_assistant/current_user/conversations
{
  "title": "The conversation title.",
  "category": "",
  "messages": [
    {
      "content": "test content",
      "role": "user",
      "isError": false,
      "timestamp": "2019-12-13T16:40:33.400Z",
      "traceData": {
        "traceId": "1234",
        "transactionId": "2",
      },
    },
  ],
  "apiConfig": {
    "actionTypeId": ".gen-ai",
    "connectorId": "86ab-471c-a00b-25b7e20c2d12",
    "defaultSystemPromptId": "Default",
    "model": "gpt-4o"
  },
  "isDefault": false,
  "excludeFromLastConversationStorage": true,
  "replacements": {
    "field1": "914beb92-86ab-471c-a00b"
  }
}
--------------------------------------------------

[discrete]
=== Response code

```
`200`::
    Indicates a successful call.
```

[discrete]
=== Response payload

A JSON Conversation object with a unique `id`.

*Example 1*

Conversation response payload:

[source,json]
--------------------------------------------------
{
  
}
--------------------------------------------------

